{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "df_whole = pd.DataFrame()\n",
    "ride_file = \"G:\\\\My Drive\\\\Cindy\\\\IB11\\\\Math IA\\\\ridedatanew\\\\rides.csv\"\n",
    "df_ride = pd.read_csv(ride_file, header=0)\n",
    "meta_file = \"G:\\\\My Drive\\\\Cindy\\\\IB11\\\\Math IA\\\\Metadata\\\\metadata.csv\"\n",
    "df_meta = pd.read_csv(meta_file, header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        date          datetime  SACTMIN  SPOSTMIN        Ride  \\\n",
      "0           0  01/01/2015   2015-01-01 8:35      NaN      10.0  SmallWorld   \n",
      "1           1  01/01/2015   2015-01-01 9:18      NaN      10.0  SmallWorld   \n",
      "2           2  01/01/2015   2015-01-01 9:52      NaN      40.0  SmallWorld   \n",
      "3           3  01/01/2015  2015-01-01 10:57      NaN      20.0  SmallWorld   \n",
      "4           4  01/01/2015  2015-01-01 10:57     33.0       NaN  SmallWorld   \n",
      "\n",
      "  oritime  Hour  Mins NewTime  Waittime  \n",
      "0   08:35     8    35   08:30      10.0  \n",
      "1   09:18     9    18   09:15      10.0  \n",
      "2   09:52     9    52   09:45      40.0  \n",
      "3   10:57    10    57   10:45      20.0  \n",
      "4   10:57    10    57   10:45      20.0  \n",
      "         DATE WDW_TICKET_SEASON  DAYOFWEEK  DAYOFYEAR  WEEKOFYEAR  \\\n",
      "0  01/01/2015               NaN          5          0           0   \n",
      "1  01/02/2015               NaN          6          1           0   \n",
      "2  01/03/2015               NaN          7          2           0   \n",
      "3  01/04/2015               NaN          1          3           1   \n",
      "4  01/05/2015               NaN          2          4           1   \n",
      "\n",
      "   MONTHOFYEAR  YEAR          SEASON  HOLIDAYPX  HOLIDAYM  ... HSFIREWKS  \\\n",
      "0            1  2015  CHRISTMAS PEAK          0         5  ...         1   \n",
      "1            1  2015       CHRISTMAS          2         5  ...         1   \n",
      "2            1  2015       CHRISTMAS          3         0  ...         1   \n",
      "3            1  2015       CHRISTMAS          4         0  ...         1   \n",
      "4            1  2015       CHRISTMAS          5         0  ...         1   \n",
      "\n",
      "   AKPRDDAY AKPRDDT1 AKPRDDT2 AKPRDDN  AKFIREN  AKSHWNGT AKSHWNT1  AKSHWNT2  \\\n",
      "0         0      NaN      NaN     NaN      NaN         0      NaN       NaN   \n",
      "1         0      NaN      NaN     NaN      NaN         0      NaN       NaN   \n",
      "2         0      NaN      NaN     NaN      NaN         0      NaN       NaN   \n",
      "3         0      NaN      NaN     NaN      NaN         0      NaN       NaN   \n",
      "4         0      NaN      NaN     NaN      NaN         0      NaN       NaN   \n",
      "\n",
      "   AKSHWNN  \n",
      "0      NaN  \n",
      "1      NaN  \n",
      "2      NaN  \n",
      "3      NaN  \n",
      "4      NaN  \n",
      "\n",
      "[5 rows x 181 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_ride.head(5))\n",
    "print(df_meta.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2015\n",
      "1    2015\n",
      "2    2015\n",
      "3    2015\n",
      "4    2015\n",
      "Name: YEAR, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_whole = pd.merge(df_ride, df_meta, left_on='date', right_on='DATE', how='inner')\n",
    "#df_meta.info()\n",
    "print(df_whole[\"YEAR\"].head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.78498955658843 29.574201150021317\n",
      "27.062681081816304 26.282697425724614\n",
      "363387 347124\n"
     ]
    }
   ],
   "source": [
    "Sun_mean=df_whole.loc[df_whole['DAYOFWEEK']==1,'Waittime'].mean()\n",
    "Thurs_mean=df_whole.loc[df_whole['DAYOFWEEK']==5,'Waittime'].mean()\n",
    "Sun_std=df_whole.loc[df_whole['DAYOFWEEK']==1,'Waittime'].std()\n",
    "Thurs_std=df_whole.loc[df_whole['DAYOFWEEK']==5,'Waittime'].std()\n",
    "no_of_Sun=df_whole.loc[df_whole['DAYOFWEEK'] ==1,'Waittime'].count()\n",
    "no_of_Thurs=df_whole.loc[df_whole['DAYOFWEEK'] ==5,'Waittime'].count()\n",
    "print(Sun_mean, Thurs_mean)\n",
    "print(Sun_std, Thurs_std)\n",
    "print(no_of_Sun, no_of_Thurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z= 19.131 p= 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from scipy.stats import norm\n",
    "def twoSampZ(X1, X2, mudiff, sd1, sd2, n1, n2):\n",
    "    pooledSE = numpy.sqrt(sd1**2/n1 + sd2**2/n2)\n",
    "    z = ((X1 - X2) - mudiff)/pooledSE\n",
    "    pval = 2*(1 - norm.cdf(abs(z)))\n",
    "    return round(z,3), pval\n",
    "z,p= twoSampZ(Sun_mean,Thurs_mean,0,Sun_std,Thurs_std,no_of_Sun,no_of_Thurs)\n",
    "print('z=', z, 'p=',p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.15984880463564 21.088168272443273\n",
      "28.711217143339475 18.01401651068867\n",
      "208472 175097\n"
     ]
    }
   ],
   "source": [
    "First_mean=df_whole.loc[df_whole['MONTHOFYEAR']==1,'Waittime'].mean()\n",
    "Second_mean=df_whole.loc[df_whole['MONTHOFYEAR']==9,'Waittime'].mean()\n",
    "First_std=df_whole.loc[df_whole['MONTHOFYEAR']==1,'Waittime'].std()\n",
    "Second_std=df_whole.loc[df_whole['MONTHOFYEAR']==9,'Waittime'].std()\n",
    "no_of_First=df_whole.loc[df_whole['MONTHOFYEAR'] ==1,'Waittime'].count()\n",
    "no_of_Second=df_whole.loc[df_whole['MONTHOFYEAR'] ==9,'Waittime'].count()\n",
    "print(First_mean, Second_mean)\n",
    "print(First_std, Second_std)\n",
    "print(no_of_First, no_of_Second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z= 158.407 p= 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from scipy.stats import norm\n",
    "def twoSampZ(X1, X2, mudiff, sd1, sd2, n1, n2):\n",
    "    pooledSE = numpy.sqrt(sd1**2/n1 + sd2**2/n2)\n",
    "    z = ((X1 - X2) - mudiff)/pooledSE\n",
    "    pval = 2*(1 - norm.cdf(abs(z)))\n",
    "    return round(z,3), pval\n",
    "z,p= twoSampZ(First_mean,Second_mean,0,First_std,Second_std,no_of_First,no_of_Second)\n",
    "print('z=', z, 'p=',p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcc = np.corrcoef(df.ApplicantIncome, df.LoanAmount)\n",
    "print(pcc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6752f5b08c1783b914aae51d910f67c7fdce8653a075e9fcde9adeff71b7d222"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
